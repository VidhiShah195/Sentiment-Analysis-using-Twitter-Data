# Sentiment Analysis using Twitter Data

## Problem 
The primary aim of the current study is to solve the problem of emotion detection by performing sentiment analysis. Sentiment analysis is a natural language processing technique used to decipher the emotional tone of text. In this case, the tone or sentiment categories analyzed are either positive or negative and the dataset is composed of data from Twitter. There are many applications for this study. For example, businesses may want to monitor the online feedback they are getting to make data-driven decisions, or brands may want to monitor their public opinion by analyzing online information. In the digital age, social media plays a huge role in marketing and businesses can receive direct feedback now more than ever. Understanding how to access and process this information is a huge asset for companies. For companies to truly gain an understanding of customer opinions and respond to market demands, this study, with the use of sentiment analysis, allows further insight than company-elicited feedback forms alone.

## Dataset
The dataset originally contained 74,996 tweets, each with four attributes: tweet ID, entity, sentiment, and the tweet content. The dataset was pre-split into a training and testing set, with 1000 rows belonging to the test subset and the rest in the training subset. The sentiment column contained “Positive”, “Negative”, “Neutral” and “Irrelevant”. To start the data cleaning process, both the “Neutral” and “Irreverent” rows were dropped. In this step, a total of 31,308 rows were dropped from the training set and 438 rows were dropped from the testing set. Next any null values were dropped from the dataset. Only the tweet content column contained null values. A total of 686 values were dropped from the training set and none from the testing set. At this time, the data set was clean and ready to process for the models, resulting in a total of 43,506 entries left in the data set: 43,506 rows in the testing set and 493 rows in the testing set. Figure 1, below, shows the value counts of each sentiment across the dataset. To prepare the data for the modeling stage of this project, “Positive” sentiment was encoded as 1, and “Negative” sentiment was encoded as 0. Neither the tweet “id” nor “entity” columns are used in the model. The tweet content is our feature variable with the tweet content as our binary target variable.

## Preprocessing
To pre-process our data and prepare it for the model, word embedding, tokenization, and sequence padding techniques were employed. The word embedding was achieved using GloVe (Global Vectors for Word Representation) to create dense vectors for each word in the tweet content column. After the dense vectors had been created and a sequence length of 50 was padded across the dataset, the data was finally cleaned and preprocessed for our modeling.

## Deep Learning Models
The study compared Long Short-Term Memory (LSTM) and Transformer models for sentiment analysis on Twitter data. 
* LSTM is known for its sequential processing and memory cell usage, and captures long-term dependencies well, making it suitable for analyzing longer text sequences like tweets.
* Transformers use attention mechanisms to excel at capturing nuanced relationships in short or long text sequences, making them effective for understanding the context and sentiment in tweets, including informal language and emojis. Overall, both models offer unique strengths for sentiment analysis tasks on Twitter data.

## Implementation
The LSTM model is designed for binary sentiment classification. The embedding layer is employed to convert input sequences into dense vectors, mapping each word to a fixed-size vector space. The model comprises three LSTM layers, each with 50 units, facilitating the capture of sequential patterns in the data. To prevent overfitting, dropout layers with a rate of 0.2 are strategically placed after each LSTM layer. The final layer is a densely connected layer with a sigmoid activation function, enabling binary sentiment prediction. The Adam optimizer is chosen for efficient weight updates during training. The model is trained for five epochs, each epoch processing batches of 32 samples, with a binary cross entropy loss function used to evaluate the difference between predicted and actual sentiments. In contrast, the Transformer model adopts a self-attention mechanism for multiclass sentiment classification. The TokenAndPositionEmbedding layer combines token and positional embeddings to represent input sequences. The TransformerBlock, composed of multi-head self-attention and feed-forward neural network components, enables the model to capture both global and local patterns efficiently. Following the transformer blocks, global average pooling and dense layers are employed to reduce dimensionality and capture overall sequence information. The final layer is a densely connected layer with a softmax activation function, facilitating multiclass sentiment predictions. Similar to the LSTM model, the Adam optimizer is utilized, but the loss function is switched to sparse categorical cross entropy to accommodate the multiclass nature of sentiment labels. The model undergoes training for five epochs with batches of 32 samples.
In summary, while both models share the Adam optimizer and a batch size of 32, their architectural differences are pronounced. The LSTM model leverages recurrent layers to capture temporal dependencies, whereas the Transformer model employs self-attention mechanisms for efficient global and local pattern recognition. These models showcase the versatility of deep learning architectures in handling diverse natural language processing tasks.

## Evaluation
LSTM and Transformers models were evaluated by focusing on accuracy and loss metrics over five epochs. The LSTM model demonstrated steady accuracy improvement, reaching a peak of 97.97% in the fourth epoch, with decreasing loss indicating improved sentiment prediction precision. In contrast, the Transformers model showed consistently high accuracy across epochs (97.24% to 97.79%), with some loss variability potentially due to rapid sentiment changes in tweets. Despite different approaches, both models performed comparably well, indicating their effectiveness in discerning sentiment in Twitter messages. The analysis highlights LSTM's improving accuracy trend and Transformers' consistent performance, offering insights into their respective strengths and weaknesses.

## Conclusion
Overall, both of these models performed extremely well with an accuracy score of approximately 98% respectively. However, the LSTM model performed slightly better when it came to the loss function. Both of these models can be helpful moving forward since the sentiment analysis will provide the company with a strong outlook of their consumers' feelings. This includes positive and negative feelings that can reinforce something good or identify something that can be improved upon. Twitter can be an extremely valuable platform for feedback, and this rings true across numerous different fields. This valuable information could help companies make more informed decisions, gain better insight into customer opinions, understand customer needs and monitor brand feedback. This study can also be applied to other sentiment analysis tasks such as product reviews or feedback surveys. 

## Lessons Learned
* Understanding the background of deep learning models is crucial for selecting the appropriate model for specific tasks.
* The choice of parameters such as the number of layers, epochs, and optimization methods significantly impacts model performance, necessitating a balance between performance and efficiency.
* Testing different configurations (e.g., varying layers, epochs, and batch sizes) provides valuable insights into model optimization but may require substantial computational resources and time.
* Despite the computational demands, optimizing model performance while maintaining efficiency yields impressive results in deep learning tasks.

## Future Work
* Consider including a Convolutional Neural Network (CNN) as a third model for comparison in sentiment analysis tasks to produce more robust results.
* Explore incorporating neutral sentiment alongside positive and negative sentiments to enhance the analysis's nuance and accuracy.
* Conduct a more comprehensive evaluation of model performance across diverse sentiment categories using techniques like confusion matrices and classification reports.

